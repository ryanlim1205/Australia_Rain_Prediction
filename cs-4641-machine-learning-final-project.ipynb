{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **CS 4641 Final Project**\n**Team Information**\n\n* Brian Lee     (903447932)\n* Hyuntaek Lim  (903336480)\n* Dowon Kim     (903218787)\n\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction\nAustralia is well-known for having the most extreme and unpredictable weather in the world. Having a tropical-influenced climate, the northern part of Australia is currently the hottest place on this planet [1]. Melbourne, a city located on the southern coast, is said to have \"four seasons in one day\".\n\nMeteorologists in Australia collect data from polar-orbiting satellites, aircrafts, and air-balloons for accurate weather forecasts. Their supercomputers utilize those data to build a \"spaghetti model,\" which is used for a week-long weather forecast by calculating the high and low pressure systems [2]. However, due to the constantly shifting weather conditions, the Australian supercomputers often fail to predict the weather correctly - the accuracy of predicting the amount of rain in Melbourne was only 24% on average [3].\n\nJust like the supercomputers, with a dataset that collected 10 years of daily weather observations in Australia, we decided to apply machine learning algorithms to predict whether it will rain the next day, which may improve the accuracy of the weather forecast. In this project, we will compare and contrast various machine learning algorithms and their predictions to possibly provide insights to meteorologists. The different Machine Learning models will be analyzed so that we can identify the factors that play significant roles in predicting the chance of showers. ","metadata":{}},{"cell_type":"markdown","source":"## 2. Dataset\n\nThe dataset contains about 10 years of daily weather observations from various locations across Australia: many different weather features that are considered to be critical to predicting rain, such as cloud, humidity, and wind are included. Basic information, such as temperature and location, is also provided.\n\nOur dataset provides the following data columns:\n\n* Date: in YYYY-MM-DD format, from 2008 to 2017\n* Location: various cities in Australia, such as Albury\n* MinTemp: the lowest temperature of the location on the correspoding date\n* MaxTemp: the highest temperature of the location on the correspoding date\n* Rainfall: the amount of rainfall in mm\n* Evaporation: the amount of dailty water evaporation in mm\n* Sunshine: the amount of hours of daily bright sunlight\n* WindGustDir: the direction of wind gust (a sudden increase in the speed of wind) \n* WindGustSpeed: the speed of wind gust in km/h\n* WindDir9am: the direction of wind at 09:00\n* WindDir3pm: the direction of wind at 15:00\n* WindSpeed9am: the speed of wind at 09:00 in km/h\n* WindSpeed3pm: the speed of wind at 15:00 in km/h\n* Humidity9am: the humidity at 09:00 in %\n* Humidity3pm: the humidity at 15:00 in %\n* Pressure9am: the atmospheric pressure at 09:00\n* Pressure3pm: the atmospheric pressure at 09:00 \n* Cloud9am: the amount of cloud at 09:00 in 8th\n* Cloud3pm: the amount of cloud at 15:00 in 8th\n* Temp9am: temperature at 09:00 in degrees celcius\n* Temp3pm: temperature at 15:00 in degrees celcius\n* RainToday: whether it rained or not (Yes or No)\n\n* **RainTomorrow: whether it rained the next day (Yes or No)  --> target variable**\n\n\nSource: [WeatherAUS](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package)\n\n**The ultimate goal of our project is to classify the binary class RainTomorrow - our target variable - which indicates whether it rained the next day based on the data provided. We will be utilizing supervised learning to prognosticate the next day's rainfall.**","metadata":{}},{"cell_type":"code","source":"# Importing the modules\n\nimport pandas as pd\n\nfrom sklearn import datasets\n\n\n\nfrom sklearn.naive_bayes import BernoulliNB           \nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:30.703934Z","iopub.execute_input":"2021-12-10T23:00:30.704467Z","iopub.status.idle":"2021-12-10T23:00:30.709360Z","shell.execute_reply.started":"2021-12-10T23:00:30.704430Z","shell.execute_reply":"2021-12-10T23:00:30.708544Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## 3. Reading the Dataset","metadata":{}},{"cell_type":"code","source":"NUM_SAMPLES = 5  # Number of samples to view\n\nDATA = pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')\nDATA.head(NUM_SAMPLES)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:30.714366Z","iopub.execute_input":"2021-12-10T23:00:30.714553Z","iopub.status.idle":"2021-12-10T23:00:31.029710Z","shell.execute_reply.started":"2021-12-10T23:00:30.714531Z","shell.execute_reply":"2021-12-10T23:00:31.028777Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# Generating shape of the data\n\nnum_rows, num_col = DATA.shape\nprint(\"# ROWS\\t\\t\", num_rows)\nprint(\"# COLUMNS\\t\", num_col)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:31.031572Z","iopub.execute_input":"2021-12-10T23:00:31.031906Z","iopub.status.idle":"2021-12-10T23:00:31.037971Z","shell.execute_reply.started":"2021-12-10T23:00:31.031867Z","shell.execute_reply":"2021-12-10T23:00:31.037079Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"In total, there are 145,460 rows and 23 columns of data.\n\n\nBefore training our models, the following problems had to be resolved through data preprocessing.\n\n1. Dropping the date column, which is not a useful feature for our prediction\n2. Filling the NaN (missing data) values, as seen in the sample data table\n3. Encoding categorical attributes, such as RainTomorrow column, into numbers\n4. Removing outliers that skew our models","metadata":{}},{"cell_type":"markdown","source":"## 4. Data Preprocessing\n\n### 4.1 Dropping the Date Column\n\n","metadata":{}},{"cell_type":"code","source":"DATA = DATA.iloc[:, 1:]\nDATA.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:31.039513Z","iopub.execute_input":"2021-12-10T23:00:31.039778Z","iopub.status.idle":"2021-12-10T23:00:31.084726Z","shell.execute_reply.started":"2021-12-10T23:00:31.039744Z","shell.execute_reply":"2021-12-10T23:00:31.083959Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"As we all can see, the data column has been deleted - now the sample data table only has 22 columns left.\n\n\n\n\n\n\n### 4.2 Handling the Missing Data\nBefore filling the missing data, we wanted to visualize and organize the missing data from the dataset. The missingno module allowed us to create a bar graph that indicates the number of missing data in each dataset column. After the visualization, we filled the missing data out through different approaches based on the data's type: continuous and categorical.","metadata":{}},{"cell_type":"code","source":"# Visualizing the missing data\n\nimport missingno\n\nmissingno.bar(DATA, sort='descending', color=\"green\")","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:31.086989Z","iopub.execute_input":"2021-12-10T23:00:31.087267Z","iopub.status.idle":"2021-12-10T23:00:32.924636Z","shell.execute_reply.started":"2021-12-10T23:00:31.087231Z","shell.execute_reply":"2021-12-10T23:00:32.923886Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Only show continuous attributes\ncont = DATA.select_dtypes(\"float64\")\ncont.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:32.927054Z","iopub.execute_input":"2021-12-10T23:00:32.927596Z","iopub.status.idle":"2021-12-10T23:00:32.956989Z","shell.execute_reply.started":"2021-12-10T23:00:32.927552Z","shell.execute_reply":"2021-12-10T23:00:32.955932Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Now, only display the number of missing values in each of the continuous attribute\ncont.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:32.958650Z","iopub.execute_input":"2021-12-10T23:00:32.959049Z","iopub.status.idle":"2021-12-10T23:00:32.975425Z","shell.execute_reply.started":"2021-12-10T23:00:32.958989Z","shell.execute_reply":"2021-12-10T23:00:32.974613Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# We need to replace the null values of our continuous data\n# The best approach to do so would be using mean to minimize the bias - continuous data are basically numbers\n\nfor col in cont:\n    DATA[col] = DATA[col].fillna(DATA[col].mean())\n\n# All of our continuous attributes now have 0 missing values\ncont = DATA.select_dtypes(\"float64\")\ncont.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:32.978302Z","iopub.execute_input":"2021-12-10T23:00:32.978481Z","iopub.status.idle":"2021-12-10T23:00:33.014802Z","shell.execute_reply.started":"2021-12-10T23:00:32.978458Z","shell.execute_reply":"2021-12-10T23:00:33.014102Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Only show categorical attributes\ncatg = DATA.select_dtypes(\"object\")\ncatg.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:33.015992Z","iopub.execute_input":"2021-12-10T23:00:33.016775Z","iopub.status.idle":"2021-12-10T23:00:33.037112Z","shell.execute_reply.started":"2021-12-10T23:00:33.016732Z","shell.execute_reply":"2021-12-10T23:00:33.036495Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# Display number of missing values in each of the categorical attribute\ncatg.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:33.038855Z","iopub.execute_input":"2021-12-10T23:00:33.039578Z","iopub.status.idle":"2021-12-10T23:00:33.128850Z","shell.execute_reply.started":"2021-12-10T23:00:33.039544Z","shell.execute_reply":"2021-12-10T23:00:33.128091Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# We need to replace null values of our categorical data\n# The best approach to do so would be using mode - categorical data are not numbers\n\nfor col in catg:\n    DATA[col] = DATA[col].fillna(DATA[col].mode()[0])\n\n# All of our categorical attributes now have 0 missing values\ncatg = DATA.select_dtypes(\"object\")\ncatg.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:33.133214Z","iopub.execute_input":"2021-12-10T23:00:33.133619Z","iopub.status.idle":"2021-12-10T23:00:33.420520Z","shell.execute_reply.started":"2021-12-10T23:00:33.133588Z","shell.execute_reply":"2021-12-10T23:00:33.419828Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Now, our dataset has no missing data\nDATA.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:33.421899Z","iopub.execute_input":"2021-12-10T23:00:33.422346Z","iopub.status.idle":"2021-12-10T23:00:33.516650Z","shell.execute_reply.started":"2021-12-10T23:00:33.422308Z","shell.execute_reply":"2021-12-10T23:00:33.515949Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"### 4.3 Encoding Categorical Attributes\n\nSince machine learning models only works with numbers, we need to encode the textual data (categorical attributes) into numbers.","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\nlabelEncoder = preprocessing.LabelEncoder()\n\nfor col in catg:\n    DATA[col] = labelEncoder.fit_transform(DATA[col])\n    \nDATA.head(NUM_SAMPLES)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:33.517777Z","iopub.execute_input":"2021-12-10T23:00:33.518078Z","iopub.status.idle":"2021-12-10T23:00:33.840763Z","shell.execute_reply.started":"2021-12-10T23:00:33.518015Z","shell.execute_reply":"2021-12-10T23:00:33.839840Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"All of the textual data have been transformed into numerical data, which can be utilized for constructing machine learning models. Comparing to the very first data table, the city \"Albury\" has changed to an integer 2, and the all of the \"No\" in RainTomorrow is now 0. Other categorical data - WindGustDir, WindDir9am, Windir3pm, and RainToday - have also been transformed.","metadata":{}},{"cell_type":"markdown","source":"### 4.4 Removing Outliers\n\nOutliers can damage the machine learning models that we plan to build; it is very imperative to clean out the extreme values in the dataset to ensure the models represent in the most effective way.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom scipy import stats\n\n# Remove outliers using z-score\n\nDATA = DATA[(np.abs(stats.zscore(DATA)) < 3).all(axis=1)]\nDATA.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:33.842378Z","iopub.execute_input":"2021-12-10T23:00:33.842730Z","iopub.status.idle":"2021-12-10T23:00:33.938717Z","shell.execute_reply.started":"2021-12-10T23:00:33.842688Z","shell.execute_reply":"2021-12-10T23:00:33.937552Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"After removing the outliers, we now have 136,608 rows that contain weather features in various cities of Australia. 8,852 rows have been deleted.","metadata":{}},{"cell_type":"markdown","source":"## 5. Data Visualization\n\nNow that we have preprocessed the data, we can visualize the \"correct\" data to figure out the correlations between the weather variables.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Using a heatmap to show the correlations between variables\nplt.figure(figsize=(17,15))\nax = sns.heatmap(DATA.corr(), square=True, annot=True, fmt='.2f',cmap=\"YlGnBu\")\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)          \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:33.940116Z","iopub.execute_input":"2021-12-10T23:00:33.940441Z","iopub.status.idle":"2021-12-10T23:00:36.490548Z","shell.execute_reply.started":"2021-12-10T23:00:33.940403Z","shell.execute_reply":"2021-12-10T23:00:36.489841Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"From the first look at the heatmap, we notice the following: \n\n* Strong correlation with RainTomorrow: RainToday, Cloud3pm, Cloud9am, Humidity3pm Humidity9am, Rainfall, and WindGustSpeed\n* Weak correlation with RainTomorrow: Sunshine, Pressure9am, Pressure3pm, and Temp3pm\n\nThis analysis intuitively makes sense. There is a high chance of precipitation the next day if the weather is rainy today, or if the humidity is high. On the other hand, if it is really sunny today, it is less likely to be rainy the next day.\n\nNow, we are ready to create and train a model.","metadata":{}},{"cell_type":"markdown","source":"## 6. Training and Testing Our Models\n\nFirst, we would need to split the dataset into testing and training sets. Then we can create a method that calculates the prediction accuracy of the different trained models. ","metadata":{}},{"cell_type":"code","source":"x = DATA.drop('RainTomorrow', axis=1)    # x = the input data\ny = DATA['RainTomorrow']                 # y = output variable\n\n# Split the dataset into testing and training sets\nfrom sklearn.model_selection import train_test_split\n\n# Test Size\ntest_size = 0.2\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size)\n\n# Evaluation\nfrom sklearn.metrics import accuracy_score\n\ndef model_accuracy(modelName, predicted):\n    accuracy = accuracy_score(y_test, predicted.round())*100\n    print(f\"Accuracy for {modelName}: \", accuracy, \"%\")\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:36.491973Z","iopub.execute_input":"2021-12-10T23:00:36.492445Z","iopub.status.idle":"2021-12-10T23:00:36.530454Z","shell.execute_reply.started":"2021-12-10T23:00:36.492412Z","shell.execute_reply":"2021-12-10T23:00:36.529589Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### 6.1 Decision Tree\nOur first model to predict the next day's precipitation is the decision tree.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# the classifier\nclf_tree = DecisionTreeClassifier()\n# training the decision tree model\ntree_model = clf_tree.fit(x_train, y_train)\n# predict!\ntree_pred = clf_tree.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:36.532165Z","iopub.execute_input":"2021-12-10T23:00:36.532461Z","iopub.status.idle":"2021-12-10T23:00:38.201201Z","shell.execute_reply.started":"2021-12-10T23:00:36.532423Z","shell.execute_reply":"2021-12-10T23:00:38.200440Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"With the trained model, we can genrate various reports that indicate the accuracy of the decision tree's predictions.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_test, tree_pred))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:38.202314Z","iopub.execute_input":"2021-12-10T23:00:38.202562Z","iopub.status.idle":"2021-12-10T23:00:38.243602Z","shell.execute_reply.started":"2021-12-10T23:00:38.202531Z","shell.execute_reply":"2021-12-10T23:00:38.242777Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"[[a b]  \n [c d]]\n \na: the model predicted negative, and it is true in real life (true negative) -> we predicted no rain, and it did not rain : 18675 cases -> Correct prediction\n\nd: the model predicted positive, and it is true in real life (true positive) -> we predicted rain, and it did rain : 2906 cases -> Correct prediciton\n\nb: the model predicted positive, but it is false in real life (false positive) -> we predicted rain, but it did not rain : 3082 cases -> Wrong prediction \n\nc: the model predicted negative, but it is false in real life (false negative) -> we predicted no rain, but it did rain : 2659 cases -> Wrong prediction\n\n\nTotal correct predictions: 21,581 cases\n\nTotal predictions: 27,322 cases\n\nThe accuracy of the decision tree's predictions is approximately 0.7899 according to the generated confusion matrix. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, tree_pred))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:38.245016Z","iopub.execute_input":"2021-12-10T23:00:38.245299Z","iopub.status.idle":"2021-12-10T23:00:38.285633Z","shell.execute_reply.started":"2021-12-10T23:00:38.245264Z","shell.execute_reply":"2021-12-10T23:00:38.284845Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":"As the classification report shows, the accuracy of the decision tree is about 0.79, which is very similar to the result of the confusion matrix. F1 score, the weighted mean of precision and recall, is also close to 1: the performance of our decision tree model is pretty good.","metadata":{}},{"cell_type":"markdown","source":"### 6.2 Gaussian Naive Bayes\n\nOur second model is Gaussian Naive Bayes.","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\n# the model\nclf_g_nb = GaussianNB()\n# training the Gaussian Naive Bayes model\ng_nb_model = clf_g_nb.fit(x_train, y_train)\n# predict!\ng_nb_pred = clf_g_nb.predict(x_test)\n\nprint(confusion_matrix(y_test, g_nb_pred))\nprint('\\n')\nprint(classification_report(y_test, g_nb_pred))","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:38.286971Z","iopub.execute_input":"2021-12-10T23:00:38.287276Z","iopub.status.idle":"2021-12-10T23:00:38.407175Z","shell.execute_reply.started":"2021-12-10T23:00:38.287241Z","shell.execute_reply":"2021-12-10T23:00:38.406418Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"Based on the confusion matrix, the calculated accuracy of the prediction is approximately (21,767 / 27,322) 0.7967. The classification report also indicates that the accuracy is 0.80.","metadata":{}},{"cell_type":"markdown","source":"### 6.3 Logistic Regression\n\nOur third machine learning model is the Logistic Regression model.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\n\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(x_train, y_train)\n\nlogreg_pred = logreg.predict(x_test)\n\nprint(classification_report(y_test, logreg_pred))\n\n\nlogit_roc_auc = roc_auc_score(y_test, logreg_pred)\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:38.408311Z","iopub.execute_input":"2021-12-10T23:00:38.408713Z","iopub.status.idle":"2021-12-10T23:00:40.217432Z","shell.execute_reply.started":"2021-12-10T23:00:38.408676Z","shell.execute_reply":"2021-12-10T23:00:40.212082Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"According to the classification report, the logistic regression predicts the rain with the highest accuracy: 0.84. \n\nIn addition, we added a ROC (receiver operating characteristic) curve that shows the diagnostic ability of binary classifiers. Here, the two parameters for the ROC curve are the rates of true positive and false positive. The blue graph represents the ratio between the true positive and false positive at another decision threshold. Also, the area below the blue graph is known as the AUC (area under the ROC curve). The closer the area is to 1.0, the better the accuracy of the logistic regression's predictions. Our area is approximately 0.69, which is not a bad result.\n\nNow, using the model_accuracy method we created, let's compute the prediction accuracy of each model and visualize them.","metadata":{}},{"cell_type":"code","source":"results = {}\n\nmodels = {\n    \"Decision Tree Classifier\" : clf_tree,\n    \"Gaussian Naive Bayes\" : clf_g_nb,\n    \"Logistic Regression\": logreg\n}\n\n# Our pipeline\nfor m in models:\n    # Selecting our model\n    model = models[m]\n    # Testing\n    model.fit(x_train, y_train)\n    # Prediction\n    predicted = model.predict(x_test)\n    # Evaluation\n    acc = model_accuracy(m, predicted)\n    # Record accuracy for the model\n    results[m] = acc\n\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\n\nlabels = results.keys()\nvalues = results.values()\nax.bar(labels,values, width=0.1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-10T23:00:40.218559Z","iopub.execute_input":"2021-12-10T23:00:40.219300Z","iopub.status.idle":"2021-12-10T23:00:43.708266Z","shell.execute_reply.started":"2021-12-10T23:00:40.219263Z","shell.execute_reply":"2021-12-10T23:00:43.707503Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"As we have gone through, the accuracies of each model - Decision Tree, Gaussian Naive Bayes, and Logistic Regression - are extremely similar to the results from classification models and confusion matrix of the different models. The Decision Tree and Gaussian Naive Bayes yielded similar accuracies, whereas the Logistic Regression was the only model which predicted more than 80%. \n\n\nWe analyzed that the Logistic Regression performed better than the Gaussian Naive Bayes because the latter model assumes that the attributes are conditionally independent. In the case where we are dealing with rain, however, all of the attributes are not conditionally independent, as seen in the correlation heatmap at Data Visualization section. Logistic Regression, on the other hand, directly measures the relationship between the input variables (x) and the results (y) using probabilities. Through building a direct function between the independent and output variables, the Logistic Regression model would perform better in weather forecasting. \n\n\nAlso, we resulted that the Logistic Regression had a higher accuracy than the Decision Tree due to the number of columns in the dataset. The disadvantages of using Logistic Regression are when the dataset includes too many outliers - making it impossible to come up with a decent linear line that separates the outputs into two - whereas the Decision Tree will perform well in that situation. In our project, though, we preprocessed the data to exclude the outliers, removing the disadvantage of the Logistic Regression model. However, the 22 columns of the dataset were a bit difficult for our Decision Tree model to handle; the textual report of the Decision Tree model included a huge amount of splits, decreasing the credibility of its predictions. ","metadata":{}},{"cell_type":"markdown","source":"[1] https://www.dailymail.co.uk/news/article-7807737/Fascinating-world-temperature-map-shows-country-hottest-place-EARTH.html\n\n[2] https://www.smh.com.au/national/i-know-i-m-a-weather-geek-but-i-d-love-to-see-that-the-bom-s-new-three-week-outlooks-20190510-p51m0u.html\n\n[3] http://weather-climate.com/ForecastAccuracyMelbourne29June2007.pdf","metadata":{}}]}